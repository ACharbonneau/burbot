---
title: "DESeq_Burbot"
author: "Amanda Charbonneau"
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    collapsed: no
    df_print: paged
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 5
    toc_float: yes
  html_notebook:
    toc: yes
    toc_depth: 5
---

```{r GlobalVariables}

#Setting a reasonable p-value threshold to be used throughout

p_cutoff <- 0.05

p_cutoff_new <- 0.05

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

FC_cutoff_original <- 0

FC_cutoff_new <- 1


#Reference level is non-cannibals
```


```{r Setup, include=FALSE}

BURdds <- readRDS("burbot_assemble_foursample.deseq2.rds")


```


#Global parameters for modeling



```{r LoadPackages, results='hide', include=FALSE}

# Install function for packages    
packages<-function(x){
  x<-as.character(match.call()[[2]])
  if (!require(x,character.only=TRUE)){
    install.packages(pkgs=x,repos="http://cran.r-project.org")
    require(x,character.only=TRUE)
  }
}

bioconductors <- function(x){
    x<- as.character(match.call()[[2]])
    if (!require(x, character.only = TRUE)){
      source("https://bioconductor.org/biocLite.R")
      biocLite(pkgs=x)
      require(x, character.only = TRUE)
    }
}

packages(MASS)
packages(ggplot2)
packages(gtools)
packages(pheatmap)
packages(cowplot)
packages(RColorBrewer)
packages(dplyr)
packages(tidyr)
packages(ggrepel)
bioconductors(DESeq2)

sessionInfo()

```


```{r GetMetadata}

burbotMeta <- BURdds@colData

burbotMeta$condition <- relevel(burbotMeta$condition, ref="P")

burbotMeta$family <- substring(rownames(burbotMeta), 1, 2)

betterBUR <- DESeqDataSetFromMatrix(counts(BURdds), design = ~ condition + family, colData = burbotMeta)

betterBUR <- DESeq( betterBUR )

rm(BURdds)

```

# Exploratory Plots

Some exploratory plots of un-modeled gene counts.

Before you do any statistical analysis, it's important to know what your data looks like. This is important for two main reasons:

  - It can help you find errors that will effect your downstream analysis
  - It can help you to choose an appropriate analysis for your data

We're going to look at the raw (and mostly raw) gene count data in a few ways.

## Heatmaps


In all the following heatmaps, samples or genes are clustered by Euclidean distance of rlog-transformed gene counts (this removed the dependence of variance on mean, and flattens out the variance across the data set, which makes the heatmaps a little easier to read). Transformed counts were *not* used for the DESeq2 analysis.

### Individuals clustered by overall expression

This is a heatmap clustering individuals by their expression levels for all genes. Essentially, this is a correlation plot. Each individual is perfectly correlated with itself (the dark blue diagonal). This plot shows two big groups. One that is all cannibals (on the left), one that is all non-cannibals (on the right). Families tend to cluster within feeding strategies/groups.

```{r PlainHeatmap, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}
#A useful first step in an RNA-seq analysis is often to assess overall similarity between samples: Which samples are similar to each other, which are different? Does this fit to the expectation from the experiment’s design? We use the R function dist to calculate the Euclidean distance between samples. To ensure we have a roughly equal contribution from all genes, we use it on the rlog-transformed data. We need to transpose the matrix of values using t, because the dist function expects the different samples to be rows of its argument, and different dimensions (here, genes) to be columns. 
#**Note that the two transformations offered by DESeq2 are provided for applications other than differential testing.** For differential testing we recommend the DESeq function applied to raw counts, as described later in this workflow, which also takes into account the dependence of the variance of counts on the mean value during the dispersion estimation step. The function rlog returns an object based on the SummarizedExperiment class that contains the rlog-transformed values in its assay slot. http://www.bioconductor.org/help/workflows/rnaseqGene/#the-deseqdataset-object-sample-information-and-the-design-formula


rld <- rlog(betterBUR, blind = FALSE)
sampleDists <- dist(t(assay(rld)))
df <- as.data.frame(colData(betterBUR)[,c("condition","family")])
sampleDistMatrix <- as.matrix( sampleDists )
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
pheatmap(sampleDistMatrix,
         clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists,
         col = colors, annotation = df, show_rownames=F)

```

### Individuals by Top 500 genes heatmap

Here we're using the same transformed counts to look at overall expression, however I've filtered out all but the top 500 most highly expressed genes (on average, across all individuals). Here, I'm only clustering by individuals on the x-axis, where the x-axis is individuals, but the y-axis is transcripts. Here, we can see that in the 500 most expressed genes, there are very few that have highly varying expression across samples. However, in these 500 genes, we can better cluster non-cannibals vs cannibals. There is still pretty good clustering of families within feeding strategy. 


```{r MiniPlainGeneHeatmap, echo=FALSE, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}

select500 <- order(rowMeans(counts(betterBUR,normalized=TRUE)),decreasing=TRUE)[1:500]

pheatmap(assay(rld)[select500,], show_rownames=T,clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists, annotation_col=df)


```

### Individuals clustered by top 500 gene expression

This plot is analogous to the first heatmap, in that I'm now showing a correlation matrix, however this is using just the top 500 most expressed genes rather than all of them. Clustering with the top 500 genes is giving us three big expression groups: cannibals, non-cannibals and a mix.

```{r MiniPlainHeatmap, echo=FALSE, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}

select500 <- order(rowMeans(counts(betterBUR,normalized=TRUE)),decreasing=TRUE)[1:500]

sampleDists <- dist(t(assay(rld)[select500,]))
sampleDistMatrix <- as.matrix( sampleDists )

pheatmap(sampleDistMatrix, show_rownames=T,clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists, annotation_col=df)


```

### PCA for overall expression

Here, instead of looking at correlations, we're doing a PCA. This takes the entire (transformed) count table and rotates it to find the set of orthagonal axes with the most variation. Here I'm always plotting PC1 vs PC2 (the most variable and second most variable axis). I'm coloring points by either family, feeding strategy, or both. Since PCA looks for the axis in the data with the most variation, what this will do is push dis-similar samples away from each other in the plot. In effect, we can see whether there are already clusters in the data from variables that we're *not* interested in and want to model *out*. 

In these plots, for instance, you can see on the top left that the Mc samples are pretty different from all the others, and that family effect might be part of why we're getting three clusters in the last heatmap. If we don't account for family in the DESeq model, we'll probably get the wrong genes. 

In the top right plot, you can see that non-cannibals and cannibals actually are pretty easily distinguishable just by overall gene expression, which is good. Once we account for family, we should have a fairly reliable gene list. 

However, if there are other meta-data factors that differ between samples we should add them into this plot and check for those *before* going forward. This would be things like batch effects, lane effects, sample extraction differences, etc.


```{r plainPCA, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}


cowplot::plot_grid( plotPCA(rld, intgroup="family"),
                    plotPCA(rld, intgroup="condition"),
                    plotPCA(rld, intgroup=c( "family", "condition")),
                           align="c", ncol=2)

```

# DESeq2 Overview


```{r BackgroundReading, eval=FALSE }
baseMean, is a just the average of the normalized count values, divided by the size factors, taken over all samples
The column log2FoldChange is the effect size estimate. It tells us how much the gene’s expression seems to have changed due to treatment with dexamethasone in comparison to untreated samples. This value is reported on a logarithmic scale to base 2: for example, a log2 fold change of 1.5 means that the gene’s expression is increased by a multiplicative factor of 21.5≈2.82.
lfcSE, the standard error estimate for the log2 fold change estimate.
stat=wald statistic
DESeq2 performs for each gene a hypothesis test to see whether evidence is sufficient to decide against the null hypothesis that there is zero effect of the treatment on the gene and that the observed difference between treatment and control was merely caused by experimental variability (i.e., the type of variability that you can expect between different samples in the same treatment group). As usual in statistics, the result of this test is reported as a p value, and it is found in the column pvalue. Remember that a p value indicates the probability that a fold change as strong as the observed one, or even stronger, would be seen under the situation described by the null hypothesis.
DESeq2 uses the Benjamini-Hochberg (BH) adjustment (Benjamini and Hochberg 1995) as implemented in the base R p.adjust function; in brief, this method calculates for each gene an adjusted p value that answers the following question: if one called significant all genes with an adjusted p value less than or equal to this gene’s adjusted p value threshold, what would be the fraction of false positives (the false discovery rate, FDR) among them, in the sense of the calculation outlined above? These values, called the BH-adjusted p values, are given in the column padj of the res object.


The DESeq2 software automatically performs independent filtering that maximizes the number of genes with adjusted p value less than a critical value (by default, alpha is set to 0.1). This automatic independent filtering is performed by, and can be controlled by, the results function.


The lfcThreshold isn't doing what you think it is doing. You could hypothetically do what you have done to get the 495 genes, which is to do a post hoc filtering on the fold changes. The problem with that is you have now destroyed any meaning for your p-values, which were testing for evidence that the fold change is different from zero.

In other words, a p-value is a test where you compare the range of Wald statistics you would expect to get if there were no differences between your groups. There will still be variation due to sampling, so you will by happenstance get some large statistics, and the p-value tells you the long run probability of seeing your observed result under the null. In the first case, the null distribution was one where the means are identical. Since your p-value was based on the null of no differences, adding in an extra criterion invalidates the original meaning of the p-value (and any multiplicity adjustment you might then make).

If you specify the lfcThreshold, you incorporate the fold change criterion into the Wald statistic, and are now testing your observed result against the values you would expect under the null distribution where the difference between the two groups is no larger than the lfc you have specified. This is a much more conservative threshold, and you should expect far fewer genes.

An alternative way to think about the difference is to note that a post hoc fold change criterion tells you that the fold change between your samples is greater than a certain value, but using lfcThreshold tests the probability that the underlying population fold change is greater than that value, which is entirely different (and what you really want to be testing).

Anyway, you should in general use something smaller like 1, or 0.585 (representing a 2-fold or 1.5-fold difference), rather than something massive like an lfcThreshold of 2. https://support.bioconductor.org/p/101504/
```


We're using `DESeq2` to estimate differential gene expression between cannibals and non-cannibals. We have `r length(colnames(betterBUR))` individuals, with reads aligned to `r length(betterBUR@rowRanges)` gene models.

`DESeq2` estimates the dispersion of the data similarly to `edgeR`, but then normalizes using 'shrinkage'; adjusting the estimate on a gene-by-gene basis by comparing the dispersion of each gene with the group-level dispersion.

This shrinkage adjustment is very useful for increasing your chances of finding 'true' positives, but it can be a little difficult to understand. The argument is, essentially, that counting and analyzing a small number of slightly fluctuating things is inherently more difficult than counting a large number of things. 

First, we have to think about what we mean when we say normal. In the case of genes, we know that expression in individuals for a given gene will *never* be exactly the same every time we measure it, even in the absence of any effect. Instead, we expect that biological systems have normal *ranges* they fall into. So, for example, if we measure the expression for one gene in 10 wild type samples, we would be shocked if each had exactly 150 transcripts, but think it normal if they all had between 100 and 200. 

With RNAseq, we don't know the *normal* value of expression for any of our genes, but we expect that it will be *easier* to decide what normal is for genes that have higher base expression. That's because the higher the base expression is, the more places there are for it to go (it's not zero bounded). For instance, if I were to tell you that for Gene A, your cannibals showed zero expression and your non-cannibals always had about 1000 transcripts, that would sound like a good gene to follow up on. But if the non-cannibals always had about 5 transcripts, then we're probably just looking at a low abundance transcript that *happened* to show up in a few non-cannibal samples. Similarly, if I tell you that Gene B has twice the expression in cannibals vs. non-cannibals, that's much more exciting if that makes the expression 100 vs 200 transcripts than if it's 5 vs 10. Further, if I told you that non-cannibals had 10 more transcripts on average than cannibals for a gene that normally has thousands of transcripts, you'd know that was not a real difference without any further information. But if normal for that gene is ten transcripts, then ten extra is a 2 fold change, and it's harder to say whether that's biologically significant. Basically, it's easier to judge whether a change is *biologically relevant* if the gene is normally highly expressed.

However, because we look for differences using logfold change, small differences like 5 vs 10 and 5 vs 0 will *dominate* your results, because that's a two fold change, and you're much more likely to find huge fold changes in small numbers than you are large ones.

Shrinkage helps fix this. It looks at the overall base expression of a gene and uses that to scale the fold change estimate. In effect, very low expression genes will need a *much* larger change in order to show up in our gene lists. And that's good. We don't want to dig through hundreds of five fold differences that are really just 1 transcript vs 5 transcript.

## MA plots

We can visualize how shrinkage helps with MA plots. These plots show the modeled gene counts on the x axis and their log fold change on the y axis. Both are made with the same model, I've just told it to ignore the shrinkage parameter to make the first one.


#### unshrunken

This plot shows what our results would look like if we didn't use shrinkage. Each dot is a gene, those in red are ones with a pvalue < `r p_cutoff`

Note that there are lots of genes that have very high log fold change values, and that they are mostly at small mean values (~10 to 100 transcripts on average). The horizontal bars across the top and bottom of the plot are points that would be off the plot, and so have a lfc greater than +/-5. 

```{r UnshrunkenMA, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}
res.noshr <- results(betterBUR, contrast=c("condition","C","P"), alpha = p_cutoff)

plotMA(res.noshr, ylim = c(-5, 5) )


```


#### Shrunken

Here is the same data, but shrunken. Note that the right hand side of the plot hasn't really changed a great deal, the genes with high base transcription levels haven't had their effects shrunken. However on the left side, there's no longer hundreds of low expression genes with enormous effect sizes. Now, only the ones that had very large effects are still shown as large effect. Similarly, now every gene above about a log 2 fold difference is significant, whereas in the first plot many genes were shown as having non-significant large effects. In the remainder of this analysis we're using these shrunken values to create gene lists.

```{r ShrunkenMA, fig.keep="last", fig.width=11, fig.path='figures/', dev=c('png', 'pdf')}
res <- lfcShrink(betterBUR, contrast=c("condition","C","P"), alpha = p_cutoff)
plotMA(res, ylim = c(-5, 5))

```




## Modeling parameters

`DESeq2` uses a modified design matrix that allows it do perform shrinkage analysis. This modification results in the intercept being the midpoint between the two predictors of interest, and makes the results table increasingly un-interpretable with increasing model complexity. Ideally, for the difference between High and Low lines, we would like to model expression as:

`~ family + condition`

Where condition C (cannibal) or P (non-cannibal) is the predictor of interest, and the effects of family is averaged out.


```{r CP contrasts with DESeq2, results='hide', include=FALSE}


## DESeq2 - C vs P, NO interaction
## contrast=c(column, numerator, denominator)
## Defaults: independentFiltering=TRUE
##log2(1.5) = 0.5849625

results_C_P <- results( betterBUR, contrast=c("condition", "C", "P"),
                        lfcThreshold = FC_cutoff_original, alpha = p_cutoff,
                        altHypothesis = "greaterAbs", independentFiltering=TRUE)


results_C_P_Ordered <- subset(as.data.frame(results_C_P)[order(results_C_P$padj),])

write.csv(results_C_P_Ordered, paste("CvP_ordered_all_lfc", FC_cutoff_original, "_p", p_cutoff,".csv", sep = ""), quote=FALSE)

results_C_P_Ordered_sub <- subset(as.data.frame(results_C_P)[order(results_C_P$padj),], padj < p_cutoff)

write.csv(results_C_P_Ordered_sub, paste("CvP_ordered_all_subset_lfc", FC_cutoff_original, "_p", p_cutoff,".csv", sep = ""), quote=FALSE)

```


## DESeq2 Model Results


I've run the model:  `~ family + condition`

Since we have only two conditions, one has to be the 'reference', that is, it's what is considered normal. Currently I have set non-cannibals as the reference, but this can be changed if it makes more biological sense the other way. 

### C vs P model summary

DESeq2 allows you to test for which differentially expressed genes are significant both statistically and biologically. So, by both the adjusted p-value and the log fold change. DESeq2 does this by testing the hypothesis that there is zero effect of the treatment on the gene and that the observed difference between treatment and control was merely caused by experimental variability (i.e., the type of variability that you can expect between different samples in the same treatment group), on a per gene basis. https://support.bioconductor.org/p/101504/

In all cases here, the adjusted pvalue is calculated using the Benjamini-Hochberg (BH) adjustment (Benjamini and Hochberg 1995), and I am running independent filtering, which dynamically maximizes the number of genes with adjusted p value less than `r p_cutoff`, and a given log2fold change, we're currently using ~`r FC_cutoff_original`, that is, any significant change between feeding strategies. 


Below is the summary table for this  model:


```{r SummaryCP}
summary(results_C_P)
```

Recall that up and down regulation refer to how the cannibals expression differs from the non-cannibals. Because this decision is somewhat arbitrary, we cannot say for certian that the directon of the effect is objectivly true. That is, for any given gene that says it is up-regulated, it could be that the cannibal fish are all expressing higher levels of that transcript OR it could equally mean that the non-cannibal fish are all expressing lower than normal levels of that transcript and the cannibal fish expression level didn't change. This is just a mathmatical truth about RNAseq experiments. The only way to determine the objective truth would be to know the true base level of expression for a gene. Generally speaking, that would mean doing targeted assays of a large number of fish and doing quantitative PCR.

#### C vs P model cutoffs

Because DESeq is simultanously using the p-value and log2fold change to determine which and how many genes are up and down regulated, post hoc filtering of the above data is *not* a statistically sound to way to look for log fold changes for values other than zero. Instead, we have to re-run the results function with the new lfc cutoff. At the top of the script, you can change the value of `FC_cutoff_new` to whatever number you like and re-run the script to get new gene lists. You can also edit the pvalue cutoff by changing the value of  `p_cutoff_new` in the same code box. Currently, the value of `FC_cutoff_new` = `r FC_cutoff_new`. Note that each time you run this code, it will write out these gene lists to your BurbotAnalysis R Project folder.

```{r CP contrasts new cutoffs, results='hide', include=FALSE}


## DESeq2 - C vs P, NO interaction
## contrast=c(column, numerator, denominator)
## Defaults: independentFiltering=TRUE
##log2(1.5) = 0.5849625

results_C_P_new <- results( betterBUR, contrast=c("condition", "C", "P"),
                        lfcThreshold = FC_cutoff_new, alpha = p_cutoff_new,
                        altHypothesis = "greaterAbs", independentFiltering=TRUE)


results_C_P_Ordered_new <- subset(as.data.frame(results_C_P_new)[order(results_C_P_new$padj),])

write.csv(results_C_P_Ordered_new, paste("CvP_ordered_all_lfc", FC_cutoff_new, "_p", p_cutoff_new, ".csv", sep=""), quote=FALSE)

results_C_P_Ordered_sub_new <- subset(as.data.frame(results_C_P_new)[order(results_C_P_new$padj),], padj < p_cutoff_new)

write.csv(results_C_P_Ordered_sub_new, paste("CvP_ordered_all_subset_lfc", FC_cutoff_new, "_p", p_cutoff_new, ".csv", sep = ""), quote=FALSE)


```

```{r SummaryCP_new}
summary(results_C_P_new)
```

### C vs P results

Here are plots of the modeled counts for the first ten genes shown in the summary for C (cannibals) vs P (non-cannibals), with an adjusted p value < `r p_cutoff_new` and a FC of at least `r 2^FC_cutoff_new` (lfc=`r FC_cutoff_new`), ordered by adjusted pvalue: 

```{r GenePlots, fig.path='figures/', dev=c('png', 'pdf')}

pdf(paste("GenePlots_lfc", FC_cutoff_new,"_p", p_cutoff_new, ".pdf", sep=""))

plotnumb <- length(results_C_P_Ordered_sub_new$baseMean)

if(plotnumb > 10){ plotnumb <- 10 }
        
for(i in 1:plotnumb){ plotCounts(betterBUR,
                          gene=rownames(results_C_P_Ordered_sub_new)[i],
                          intgroup=c("condition"), pch=16)}
                                
```


```{r GenePlotsHTML}
for(i in 1:plotnumb){ plotCounts(betterBUR,
                          gene=rownames(results_C_P_Ordered_sub_new)[i],
                          intgroup=c("condition"), pch=16)}
```

